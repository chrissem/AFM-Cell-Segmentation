{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model5LHzc import *\n",
    "from data_1ch import *\n",
    "\n",
    "vid=\"v001_5\" #version id should match the file number \n",
    "# The final number can be [1:5] and denote the cross-validation order\n",
    "# Ran DellWS with GeForce RTX3060 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiryakiv\\miniconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "LR=1e-3\n",
    "loss=dice_loss\n",
    "model = unet(LR, loss)\n",
    "testGene = testGenerator(\"afm_cell_512/test/predh\")\n",
    "model.load_weights(\"files/unet_cell_seg_\"+vid+\".hdf5\")\n",
    "results = model.predict_generator(testGene,4,verbose=1)\n",
    "saveResult(\"afm_cell_512/test/predh\",results,vid[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiryakiv\\miniconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 images belonging to 1 classes.\n",
      "Found 24 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2421 - acc: 0.9231 - dice_coef: 0.7579Found 6 images belonging to 1 classes.\n",
      "Found 6 images belonging to 1 classes.\n",
      "160/160 [==============================] - 50s 233ms/step - loss: 0.2421 - acc: 0.9231 - dice_coef: 0.7579 - val_loss: 0.8693 - val_acc: 0.7344 - val_dice_coef: 0.1307\n",
      "\n",
      "Epoch 00001: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 36s 225ms/step - loss: 0.1296 - acc: 0.9500 - dice_coef: 0.8704 - val_loss: 0.7019 - val_acc: 0.7880 - val_dice_coef: 0.2981\n",
      "\n",
      "Epoch 00002: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 36s 227ms/step - loss: 0.0762 - acc: 0.9688 - dice_coef: 0.9238 - val_loss: 0.1878 - val_acc: 0.9395 - val_dice_coef: 0.8122\n",
      "\n",
      "Epoch 00003: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 36s 224ms/step - loss: 0.0691 - acc: 0.9706 - dice_coef: 0.9309 - val_loss: 0.0987 - val_acc: 0.9687 - val_dice_coef: 0.9013\n",
      "\n",
      "Epoch 00004: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 36s 225ms/step - loss: 0.0756 - acc: 0.9666 - dice_coef: 0.9244 - val_loss: 0.0563 - val_acc: 0.9736 - val_dice_coef: 0.9437\n",
      "\n",
      "Epoch 00005: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 35s 222ms/step - loss: 0.0495 - acc: 0.9777 - dice_coef: 0.9505 - val_loss: 0.0396 - val_acc: 0.9766 - val_dice_coef: 0.9604\n",
      "\n",
      "Epoch 00006: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 37s 230ms/step - loss: 0.0467 - acc: 0.9787 - dice_coef: 0.9533 - val_loss: 0.0393 - val_acc: 0.9815 - val_dice_coef: 0.9607\n",
      "\n",
      "Epoch 00007: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 36s 227ms/step - loss: 0.0386 - acc: 0.9828 - dice_coef: 0.9614 - val_loss: 0.0371 - val_acc: 0.9859 - val_dice_coef: 0.9629\n",
      "\n",
      "Epoch 00008: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 36s 228ms/step - loss: 0.0394 - acc: 0.9821 - dice_coef: 0.9606 - val_loss: 0.0459 - val_acc: 0.9774 - val_dice_coef: 0.9541\n",
      "\n",
      "Epoch 00009: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 36s 225ms/step - loss: 0.0414 - acc: 0.9808 - dice_coef: 0.9586 - val_loss: 0.0759 - val_acc: 0.9556 - val_dice_coef: 0.9241\n",
      "\n",
      "Epoch 00010: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 36s 226ms/step - loss: 0.0385 - acc: 0.9822 - dice_coef: 0.9615 - val_loss: 0.0337 - val_acc: 0.9831 - val_dice_coef: 0.9663\n",
      "\n",
      "Epoch 00011: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 36s 227ms/step - loss: 0.0330 - acc: 0.9850 - dice_coef: 0.9670 - val_loss: 0.2899 - val_acc: 0.8271 - val_dice_coef: 0.7101\n",
      "\n",
      "Epoch 00012: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 36s 224ms/step - loss: 0.0427 - acc: 0.9803 - dice_coef: 0.9573 - val_loss: 0.0376 - val_acc: 0.9822 - val_dice_coef: 0.9624\n",
      "\n",
      "Epoch 00013: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 36s 226ms/step - loss: 0.0349 - acc: 0.9840 - dice_coef: 0.9651 - val_loss: 0.0388 - val_acc: 0.9806 - val_dice_coef: 0.9612\n",
      "\n",
      "Epoch 00014: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 36s 228ms/step - loss: 0.0316 - acc: 0.9853 - dice_coef: 0.9684 - val_loss: 0.0298 - val_acc: 0.9851 - val_dice_coef: 0.9702\n",
      "\n",
      "Epoch 00015: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 36s 223ms/step - loss: 0.0317 - acc: 0.9857 - dice_coef: 0.9683 - val_loss: 0.0282 - val_acc: 0.9854 - val_dice_coef: 0.9718\n",
      "\n",
      "Epoch 00016: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 36s 226ms/step - loss: 0.0299 - acc: 0.9860 - dice_coef: 0.9701 - val_loss: 0.0304 - val_acc: 0.9849 - val_dice_coef: 0.9696\n",
      "\n",
      "Epoch 00017: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 36s 226ms/step - loss: 0.0306 - acc: 0.9860 - dice_coef: 0.9694 - val_loss: 0.0291 - val_acc: 0.9815 - val_dice_coef: 0.9709\n",
      "\n",
      "Epoch 00018: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 36s 223ms/step - loss: 0.0305 - acc: 0.9861 - dice_coef: 0.9695 - val_loss: 0.0320 - val_acc: 0.9854 - val_dice_coef: 0.9680\n",
      "\n",
      "Epoch 00019: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 36s 225ms/step - loss: 0.0306 - acc: 0.9861 - dice_coef: 0.9694 - val_loss: 0.0264 - val_acc: 0.9879 - val_dice_coef: 0.9736\n",
      "\n",
      "Epoch 00020: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 36s 223ms/step - loss: 0.0299 - acc: 0.9862 - dice_coef: 0.9701 - val_loss: 0.0285 - val_acc: 0.9858 - val_dice_coef: 0.9715\n",
      "\n",
      "Epoch 00021: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 36s 224ms/step - loss: 0.0306 - acc: 0.9861 - dice_coef: 0.9694 - val_loss: 0.0273 - val_acc: 0.9828 - val_dice_coef: 0.9727\n",
      "\n",
      "Epoch 00022: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 36s 225ms/step - loss: 0.0301 - acc: 0.9861 - dice_coef: 0.9699 - val_loss: 0.0278 - val_acc: 0.9855 - val_dice_coef: 0.9722\n",
      "\n",
      "Epoch 00023: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 36s 226ms/step - loss: 0.0295 - acc: 0.9862 - dice_coef: 0.9705 - val_loss: 0.0359 - val_acc: 0.9869 - val_dice_coef: 0.9641\n",
      "\n",
      "Epoch 00024: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 37s 230ms/step - loss: 0.0301 - acc: 0.9863 - dice_coef: 0.9699 - val_loss: 0.0281 - val_acc: 0.9860 - val_dice_coef: 0.9719\n",
      "\n",
      "Epoch 00025: saving model to files\\unet_cell_seg_v001_5.hdf5\n",
      "Epoch 00025: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f1cf2e2b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "\n",
    "#Data augmentation\n",
    "data_gen_args = dict(rotation_range=45,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='wrap')\n",
    "\n",
    "# SETTINGS ***\n",
    "batch_size=3\n",
    "LR=1e-3\n",
    "\n",
    "train_gen = trainGenerator(batch_size,'afm_cell_512/train0'+vid[-1],'afmheight','labels',data_gen_args,save_to_dir = None)\n",
    "valid_gen = trainGenerator(batch_size,'afm_cell_512/valid0'+vid[-1],'afmheight','labels',data_gen_args,save_to_dir = None)\n",
    "\n",
    "# 24 images are used for training, 6 images for validating and 4 images for testing\n",
    "train_steps = 24//batch_size\n",
    "valid_steps = 6//batch_size\n",
    "\n",
    "# SETTINGS ***\n",
    "loss=dice_loss\n",
    "steps_per_epoch=20*train_steps\n",
    "num_epochs=100\n",
    "\n",
    "model = unet(LR, loss)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(LR)\n",
    "metrics = [\"acc\", dice_coef]\n",
    "model.compile(loss=dice_loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "callbacks = [\n",
    "             ModelCheckpoint('files/unet_cell_seg_'+vid+'.hdf5', verbose=1, save_best_model=True),\n",
    "             ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-8),\n",
    "             CSVLogger(\"files/data_\"+vid+\".csv\"),\n",
    "             EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "            ]\n",
    "\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, steps_per_epoch=steps_per_epoch, validation_steps=valid_steps, \n",
    "                    epochs=num_epochs, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate your model and save predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiryakiv\\miniconda3\\envs\\tf-latest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 73ms/step\n"
     ]
    }
   ],
   "source": [
    "validGene = testGenerator(\"afm_cell_512/valid0\"+vid[-1]+\"/predh\")\n",
    "model.load_weights(\"files/unet_cell_seg_\"+vid+\".hdf5\")\n",
    "results = model.predict_generator(validGene,6,verbose=1)\n",
    "saveResult(\"afm_cell_512/valid0\"+vid[-1]+\"/predh\",results,vid[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 512, 512, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 16) 2320        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 512, 512, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 16) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 32) 4640        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 256, 256, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 32) 9248        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 256, 256, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 128, 128, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 36928       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 128, 128, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 128)  147584      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 256)  590080      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 64, 256)  0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  131200      up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 64, 128)  0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 64, 64, 128)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 256)  0           dropout[0][0]                    \n",
      "                                                                 leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  295040      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 64, 64, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 128)  147584      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 64, 64, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 128 0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 64) 32832       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 64) 256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 128, 128, 64) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 64) 0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 128 0           leaky_re_lu_5[0][0]              \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 128, 128, 64) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 36928       leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 128, 128, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 64) 0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 32) 8224        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 256, 256, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 64) 0           leaky_re_lu_3[0][0]              \n",
      "                                                                 leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256, 256, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 256, 256, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 32) 9248        leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 32) 128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 256, 256, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 32) 0           leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 512, 512, 16) 2064        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 512, 512, 16) 64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 512, 512, 16) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512, 512, 16) 0           leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 32) 0           leaky_re_lu_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 512, 512, 16) 4624        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 512, 512, 16) 64          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 512, 512, 16) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 512, 512, 16) 2320        leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 512, 512, 16) 64          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 512, 512, 16) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 512, 512, 1)  17          leaky_re_lu_21[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,947,153\n",
      "Trainable params: 1,943,985\n",
      "Non-trainable params: 3,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntestGene = testGenerator(\"afm_cell_512/test/predh\")\\nmodel = tf.keras.models.load_model(\"files/unet_cell_seg_\"+vid+\".hdf5\",custom_objects={\\'dice_loss\\': dice_loss,\\'dice_coef\\':dice_coef})\\nresults = model.predict_generator(testGene,4,verbose=1)\\nsaveResult(\"afm_cell_512/test/predh\",results,vid)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "testGene = testGenerator(\"afm_cell_512/test/predh\")\n",
    "model = tf.keras.models.load_model(\"files/unet_cell_seg_\"+vid+\".hdf5\",custom_objects={'dice_loss': dice_loss,'dice_coef':dice_coef})\n",
    "results = model.predict_generator(testGene,4,verbose=1)\n",
    "saveResult(\"afm_cell_512/test/predh\",results,vid)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-latest",
   "language": "python",
   "name": "tf-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
